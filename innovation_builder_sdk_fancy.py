# streamlit_app.py

# -------------------------
# Imports
# -------------------------
import os
import json
import tempfile
import asyncio
import datetime
import streamlit as st
from io import StringIO

# LangChain / RAG bits - minimal imports to avoid conflicts
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI

# Alternative text splitter if needed
import re

# OpenAI Agents SDK
from agents import Agent, Runner, function_tool, ModelSettings

# -------------------------
# Helper Functions
# -------------------------
def create_download_content(topics, initial_idea, technical_output, market_output, final_output, pdf_name):
    """
    Create formatted content for download
    """
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    content = f"""
DEEPTECH INNOVATION BUILDER - ANALYSIS REPORT
=============================================
Generated on: {timestamp}
Source PDF: {pdf_name}
Powered by: OpenAI Agents SDK & LangChain

üéØ IDENTIFIED PATENT THEMES
===========================
{topics}

üöÄ INITIAL PRODUCT CONCEPT
==========================
{initial_idea}

üîß TECHNICAL OPTIMIZATION
=========================
{technical_output}

üìà MARKET OPTIMIZATION
======================
{market_output}

‚ú® FINAL PRODUCT RECOMMENDATION
==============================
{final_output}

---
Report generated by Deeptech Innovation Builder
Created by Dries Faems | LinkedIn: https://www.linkedin.com/in/dries-faems-0371569/
"""
    return content

def display_fancy_section(title, content, icon="üîç", expanded=True):
    """
    Display content in a fancy expandable section
    """
    with st.expander(f"{icon} {title}", expanded=expanded):
        st.markdown(content)

def create_progress_bar(step, total_steps, step_name):
    """
    Create a fancy progress bar
    """
    progress = step / total_steps
    st.progress(progress)
    st.write(f"**Step {step}/{total_steps}:** {step_name}")

def show_fancy_success(message):
    """
    Display a fancy success message
    """
    st.success(f"‚úÖ {message}")

def show_fancy_info(message):
    """
    Display a fancy info message
    """
    st.info(f"‚ÑπÔ∏è {message}")

def show_fancy_warning(message):
    """
    Display a fancy warning message
    """
    st.warning(f"‚ö†Ô∏è {message}")

def show_fancy_error(message):
    """
    Display a fancy error message
    """
    st.error(f"‚ùå {message}")
def simple_text_splitter(text, chunk_size=1500, chunk_overlap=150):
    """
    Simple text splitter that doesn't rely on LangChain text splitters
    """
    # Split by paragraphs first
    paragraphs = text.split('\n\n')
    chunks = []
    current_chunk = ""
    
    for paragraph in paragraphs:
        # If adding this paragraph would exceed chunk size, start a new chunk
        if len(current_chunk) + len(paragraph) > chunk_size and current_chunk:
            chunks.append(current_chunk.strip())
            # Start new chunk with overlap
            current_chunk = current_chunk[-chunk_overlap:] + paragraph
        else:
            current_chunk += "\n\n" + paragraph if current_chunk else paragraph
    
    # Add the last chunk
    if current_chunk.strip():
        chunks.append(current_chunk.strip())
    
    return chunks

def create_simple_documents(chunks):
    """Create simple document objects from text chunks"""
    class SimpleDocument:
        def __init__(self, content):
            self.page_content = content
            self.metadata = {}
    
    return [SimpleDocument(chunk) for chunk in chunks]

def simple_rag_query(vectorstore, llm, question, k=4):
    """
    Simple RAG implementation without complex chains
    """
    try:
        # Get relevant documents
        docs = vectorstore.similarity_search(question, k=k)
        
        # Combine context
        context = "\n\n".join([doc.page_content for doc in docs])
        
        # Create prompt
        prompt = f"""Answer the question based on the following patent context:

CONTEXT:
{context}

QUESTION: {question}

ANSWER: Please provide a detailed answer based only on the patent information provided above."""

        # Get response from LLM
        response = llm.invoke(prompt)
        
        # Handle different response types
        if hasattr(response, 'content'):
            return response.content
        else:
            return str(response)
            
    except Exception as e:
        return f"Error in RAG query: {str(e)}"

def run_async_in_streamlit(coro):
    """
    Helper function to run async operations safely in Streamlit
    """
    try:
        # Try to get the current event loop
        loop = asyncio.get_event_loop()
    except RuntimeError:
        # No event loop in current thread, create a new one
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
    
    try:
        return loop.run_until_complete(coro)
    except RuntimeError as e:
        if "cannot be called from a running event loop" in str(e):
            # If we're in a running loop, create a new thread
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(asyncio.run, coro)
                return future.result()
        else:
            raise

def safe_runner_sync(agent, prompt):
    """
    Safely run Runner.run_sync in Streamlit context
    """
    try:
        return Runner.run_sync(agent, prompt)
    except Exception as e:
        error_str = str(e)
        if "no current event loop" in error_str or "ScriptRunner" in error_str:
            # Handle the event loop issue
            async def run_agent():
                # Use the async version if available, otherwise wrap sync call
                try:
                    return await Runner.run(agent, prompt)
                except AttributeError:
                    # If no async version, create a new event loop
                    return Runner.run_sync(agent, prompt)
            
            return run_async_in_streamlit(run_agent())
        elif "MaxTurnsExceeded" in error_str:
            # Handle max turns exceeded - create a fallback response
            class FallbackResult:
                def __init__(self, message):
                    self.final_output = message
                    
            fallback_msg = f"Agent reached maximum turns. Agent: {agent.name}\nTask was: {prompt[:200]}...\nThis might be due to tool failures or complex reasoning loops."
            return FallbackResult(fallback_msg)
        else:
            raise

# -------------------------
# App header with fancy styling
# -------------------------
st.set_page_config(
    page_title="Deeptech Innovation Builder",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for fancy styling
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 2rem 0;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .step-container {
        background-color: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid #667eea;
        margin: 1rem 0;
    }
    .result-container {
        background-color: #ffffff;
        padding: 2rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 1rem 0;
    }
    .download-section {
        background-color: #e8f5e8;
        padding: 1.5rem;
        border-radius: 10px;
        border: 2px dashed #28a745;
        text-align: center;
        margin: 2rem 0;
    }
</style>
""", unsafe_allow_html=True)

st.markdown("""
<div class="main-header">
    <h1>üöÄ Deeptech Innovation Builder</h1>
    <p>Transform Patent Knowledge into Revolutionary Product Ideas</p>
    <p><em>Powered by AI Agents & Advanced RAG Technology</em></p>
</div>
""", unsafe_allow_html=True)

# Sidebar with instructions and info
with st.sidebar:
    st.markdown("### üìã How it works")
    st.markdown("""
    1. **üîë API Key**: Enter your OpenAI API key
    2. **üìÑ Upload PDF**: Upload patent document(s)
    3. **üöÄ Generate**: Click confirm to start analysis
    4. **üìä Review**: Explore generated insights
    5. **üíæ Download**: Save results as text file
    """)
    
    st.markdown("### üõ†Ô∏è Technology Stack")
    st.markdown("""
    - **OpenAI Agents SDK**: Multi-agent orchestration
    - **LangChain**: Document processing & RAG
    - **FAISS**: Vector similarity search
    - **Streamlit**: Interactive web interface
    """)
    
    st.markdown("### üë®‚Äçüíº About")
    st.markdown("""
    Created by **Dries Faems**  
    [LinkedIn Profile](https://www.linkedin.com/in/dries-faems-0371569/)
    """)

# Create two columns for better layout
col1, col2 = st.columns([2, 1])

with col1:
    st.markdown("### üîë OpenAI API Configuration")
    api_key = st.text_input(
        "Enter your OpenAI API Key",
        type="password",
        help="Get your API key from https://platform.openai.com/api-keys"
    )

with col2:
    st.markdown("### üìÑ Patent Document Upload")
    uploaded_file = st.file_uploader(
        "Upload Patent PDF",
        type="pdf",
        help="Upload a PDF containing patent descriptions and technical details"
    )

# Status indicators
if api_key:
    show_fancy_success("API Key provided")
else:
    show_fancy_info("Please provide your OpenAI API key to continue")

if uploaded_file:
    show_fancy_success(f"PDF uploaded: {uploaded_file.name}")
    st.info(f"üìä File size: {len(uploaded_file.getvalue())/1024:.1f} KB")
else:
    show_fancy_info("Please upload a patent PDF document")

# -------------------------
# Main action with fancy UI
# -------------------------
if st.button("üöÄ Start Innovation Analysis", type="primary", use_container_width=True) and api_key and uploaded_file:
    
    # Initialize session state for results
    if 'analysis_results' not in st.session_state:
        st.session_state.analysis_results = {}
    
    # Validate API key format first
    if not api_key.startswith('sk-') or len(api_key) < 40:
        show_fancy_error("Invalid OpenAI API key format. Please check your API key and try again.")
        st.stop()
    
    # make key available to both LangChain + Agents SDK
    os.environ["OPENAI_API_KEY"] = api_key
    
    # Create main progress container
    progress_container = st.container()
    
    with progress_container:
        st.markdown("### üîÑ Analysis Progress")
        
        # Step 1: API Key validation
        create_progress_bar(1, 6, "Validating API Key")
        try:
            test_client = ChatOpenAI(
                temperature=0.0,
                model="gpt-4o-mini",
                openai_api_key=api_key,
            )
            test_response = test_client.invoke("Hello")
            show_fancy_success("API key validated successfully")
        except Exception as e:
            show_fancy_error(f"API key validation failed: {str(e)}")
            st.stop()

        # Step 2: PDF Processing
        create_progress_bar(2, 6, "Processing Patent Document")
        
        with st.spinner("üîç Analyzing patent document..."):
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                    tmp.write(uploaded_file.read())
                    pdf_path = tmp.name

                # Load PDF -> docs with progress
                loaders = [PyPDFLoader(pdf_path)]
                docs = []
                for loader in loaders:
                    docs.extend(loader.load())
                
                if not docs:
                    show_fancy_error("No content could be extracted from the PDF. Please check the file.")
                    st.stop()
                
                show_fancy_success(f"Extracted content from {len(docs)} pages")

                # Combine all document text
                full_text = "\n\n".join([doc.page_content for doc in docs])
                
                # Use our custom text splitter
                text_chunks = simple_text_splitter(full_text, chunk_size=1500, chunk_overlap=150)
                
                if not text_chunks:
                    show_fancy_error("No text chunks could be created from the PDF.")
                    st.stop()
                
                # Create simple document objects
                splits = create_simple_documents(text_chunks)
                    
                show_fancy_success(f"Created {len(splits)} searchable text chunks")

                # Create knowledge base
                embeddings = OpenAIEmbeddings(
                    openai_api_key=api_key,
                    model="text-embedding-3-small"
                )
                vectorstore = FAISS.from_documents(splits, embeddings)
                show_fancy_success("Knowledge base created successfully")

                # Create simple RAG setup
                rag_llm = ChatOpenAI(
                    temperature=0.0,
                    model="gpt-4o-mini",
                    openai_api_key=api_key,
                )
                
                # Store LLM for use in knowledge_search function
                global rag_llm_global
                rag_llm_global = rag_llm
                
                # Test knowledge base
                test_result = vectorstore.similarity_search("patent", k=2)
                if test_result:
                    show_fancy_success("Knowledge base operational and ready")
                else:
                    show_fancy_warning("Knowledge base test returned limited results")
                    
            except Exception as e:
                show_fancy_error(f"Error processing PDF: {str(e)}")
                st.stop()

        # Define RAG tool as an Agents SDK function tool
        @function_tool
        def knowledge_search(question: str) -> str:
            """
            Search ONLY within the provided patent knowledge base.
            Args:
                question: The question to answer from the uploaded patent PDF.
            """
            try:
                # Debug: Check if we have documents
                if not splits:
                    return "ERROR: No patent documents were processed. Please ensure the PDF was uploaded correctly."
                
                # Debug: Show how many documents we have
                num_docs = len(splits)
                
                # Use our simple RAG function
                answer = simple_rag_query(vectorstore, rag_llm_global, question, k=4)
                
                # Add some context about the search
                if answer and answer.strip():
                    return f"Based on {num_docs} patent document chunks:\n\n{answer}"
                else:
                    # If no answer, try a direct retrieval approach
                    docs = vectorstore.similarity_search(question, k=3)
                    if docs:
                        context = "\n\n".join([doc.page_content[:500] for doc in docs])
                        return f"Found {len(docs)} relevant patent sections:\n\n{context}"
                    else:
                        return "No relevant patent information found for your question."
                        
            except Exception as e:
                # More detailed error reporting
                import traceback
                error_details = traceback.format_exc()
                return f"KNOWLEDGE_SEARCH_ERROR: {str(e)}\n\nDetailed error:\n{error_details}"

        # Step 3: Setup AI Agents
        create_progress_bar(3, 6, "Initializing AI Agent Team")
        
        # Model settings common to most agents
        default_model = "gpt-4o-mini"
        default_settings = ModelSettings(temperature=0.0)

        # Create the AI agent team
        topic_identification_specialist = Agent(
            name="Topic Identification Specialist",
            instructions=(
                "You are great at summarizing topics from the provided patent database. "
                "Task: Summarize the three most common themes in the patents. "
                "IMPORTANT: Call the knowledge_search tool ONCE with a broad query like 'what are the main technologies and topics covered in these patents?' "
                "If the tool returns an error, provide three general technology themes based on common patent areas. "
                "Return exactly three topics in this format:\n"
                "1. [Topic Name]: [Brief description]\n"
                "2. [Topic Name]: [Brief description]\n"
                "3. [Topic Name]: [Brief description]"
            ),
            tools=[knowledge_search],
            model=default_model,
            model_settings=default_settings,
        )

        product_development_specialist = Agent(
            name="Product Development Specialist",
            instructions=(
                "You are a seasoned product developer. "
                "Use the three identified topics and the knowledge_search tool to generate "
                "ONE concrete, novel product concept that recombines specific patent ideas. "
                "Be very specific and cite which patent fragments (as found by the tool) "
                "justify your design. Return two sections:\n"
                "1) Product Description (clear, compelling)\n"
                "2) Patents Leveraged (bulleted list: patent IDs/titles or distinctive snippets)"
            ),
            tools=[knowledge_search],
            model=default_model,
            model_settings=default_settings,
        )

        technical_expert = Agent(
            name="Technical Expert",
            instructions=(
                "You optimize product ideas based on technological feasibility and innovativeness. "
                "Given a product concept, refine it to be technically realistic, specify key "
                "subsystems, components, and risks, and suggest a minimal prototype plan."
            ),
            model=default_model,
            model_settings=default_settings,
        )

        market_expert = Agent(
            name="Competition Expert",
            instructions=(
                "You identify optimal customers and market positioning. "
                "Given a product concept, propose ICP(s), use cases, willingness-to-pay anchors, "
                "and 3 differentiators vs. existing solutions. If helpful, call knowledge_search "
                "to ground claims with patent context."
            ),
            tools=[knowledge_search],
            model=default_model,
            model_settings=default_settings,
        )

        finalization_expert = Agent(
            name="Finalization Expert",
            instructions=(
                "Combine the technical and market optimizations into a crisp final description. "
                "Return:\n"
                "‚Ä¢ Final Product Description (1‚Äì2 paragraphs)\n"
                "‚Ä¢ Key Tech Decisions (bulleted)\n"
                "‚Ä¢ Target Customers & Positioning (bulleted)\n"
                "‚Ä¢ Patents Leveraged (bulleted)\n"
                "‚Ä¢ Next 3 Steps"
            ),
            model=default_model,
            model_settings=default_settings,
        )
        
        show_fancy_success("AI Agent team assembled and ready")

        # Step 4: Topic Analysis
        create_progress_bar(4, 6, "Analyzing Patent Themes")
        with st.spinner("üîç AI agents analyzing patent themes..."):
            topics = safe_runner_sync(
                topic_identification_specialist,
                "Summarize the three most common topics in the provided patent database."
            ).final_output
            st.session_state.analysis_results['topics'] = topics

        # Step 5: Product Ideation
        create_progress_bar(5, 6, "Generating Innovation Concepts")
        with st.spinner("üí° AI agents generating product concepts..."):
            product_prompt = (
                "Using the topics below, ideate a novel product. "
                "You may call knowledge_search to ground details.\n\n"
                f"TOPICS:\n{topics}\n\n"
                "Return exactly the two sections requested."
            )
            product_result = safe_runner_sync(product_development_specialist, product_prompt)
            initial_idea = product_result.final_output
            st.session_state.analysis_results['initial_idea'] = initial_idea

        # Parallel optimization (technical and market)
        with st.spinner("üîß AI agents optimizing technical aspects..."):
            technical_output = safe_runner_sync(
                technical_expert,
                f"Engage in a technical optimization of the following product idea:\n\n{initial_idea}"
            ).final_output
            st.session_state.analysis_results['technical_output'] = technical_output

        with st.spinner("üìà AI agents analyzing market potential..."):
            market_output = safe_runner_sync(
                market_expert,
                f"Engage in a market optimization where you identify the optimal customer segment "
                f"and optimize accordingly for the following idea:\n\n{initial_idea}"
            ).final_output
            st.session_state.analysis_results['market_output'] = market_output

        # Step 6: Final Integration
        create_progress_bar(6, 6, "Finalizing Innovation Strategy")
        with st.spinner("‚ú® AI agents creating final recommendation..."):
            final_prompt = (
                "Craft the final product description using both optimizations below.\n\n"
                f"INITIAL IDEA:\n{initial_idea}\n\n"
                f"TECHNICAL OPTIMIZATION:\n{technical_output}\n\n"
                f"MARKET OPTIMIZATION:\n{market_output}\n\n"
                "Follow the exact output structure requested in your instructions."
            )
            final_output = safe_runner_sync(finalization_expert, final_prompt).final_output
            st.session_state.analysis_results['final_output'] = final_output

        show_fancy_success("Innovation analysis completed successfully!")

    # -------------------------
    # Results Display Section
    # -------------------------
    st.markdown("---")
    st.markdown("## üìä Innovation Analysis Results")
    
    # Create tabs for organized display
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üéØ Patent Themes", 
        "üí° Initial Concept", 
        "üîß Technical Analysis", 
        "üìà Market Analysis", 
        "‚ú® Final Recommendation"
    ])
    
    with tab1:
        st.markdown("### üéØ Identified Patent Themes")
        st.markdown(
            f"""
            <div class="result-container">
                {st.session_state.analysis_results['topics']}
            </div>
            """, 
            unsafe_allow_html=True
        )
    
    with tab2:
        st.markdown("### üí° Initial Product Concept")
        st.markdown(
            f"""
            <div class="result-container">
                {st.session_state.analysis_results['initial_idea']}
            </div>
            """, 
            unsafe_allow_html=True
        )
    
    with tab3:
        st.markdown("### üîß Technical Optimization")
        st.markdown(
            f"""
            <div class="result-container">
                {st.session_state.analysis_results['technical_output']}
            </div>
            """, 
            unsafe_allow_html=True
        )
    
    with tab4:
        st.markdown("### üìà Market Analysis")
        st.markdown(
            f"""
            <div class="result-container">
                {st.session_state.analysis_results['market_output']}
            </div>
            """, 
            unsafe_allow_html=True
        )
    
    with tab5:
        st.markdown("### ‚ú® Final Innovation Recommendation")
        st.markdown(
            f"""
            <div class="result-container">
                {st.session_state.analysis_results['final_output']}
            </div>
            """, 
            unsafe_allow_html=True
        )

    # -------------------------
    # Download Section
    # -------------------------
    st.markdown("---")
    st.markdown(
        """
        <div class="download-section">
            <h3>üíæ Download Complete Analysis Report</h3>
            <p>Get a comprehensive text file with all analysis results</p>
        </div>
        """, 
        unsafe_allow_html=True
    )
    
    # Create download content
    download_content = create_download_content(
        st.session_state.analysis_results['topics'],
        st.session_state.analysis_results['initial_idea'],
        st.session_state.analysis_results['technical_output'],
        st.session_state.analysis_results['market_output'],
        st.session_state.analysis_results['final_output'],
        uploaded_file.name
    )
    
    # Generate filename with timestamp
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"innovation_analysis_{timestamp}.txt"
    
    # Download button
    st.download_button(
        label="üì• Download Full Report (.txt)",
        data=download_content,
        file_name=filename,
        mime="text/plain",
        type="primary",
        use_container_width=True
    )
    
    # Additional download options
    col1, col2 = st.columns(2)
    
    with col1:
        # JSON download option
        json_content = json.dumps(st.session_state.analysis_results, indent=2)
        st.download_button(
            label="üìã Download as JSON",
            data=json_content,
            file_name=f"innovation_data_{timestamp}.json",
            mime="application/json"
        )
    
    with col2:
        # Summary download option
        summary_content = f"""Innovation Summary - {uploaded_file.name}
Generated: {datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

FINAL RECOMMENDATION:
{st.session_state.analysis_results['final_output']}
"""
        st.download_button(
            label="üìÑ Download Summary",
            data=summary_content,
            file_name=f"innovation_summary_{timestamp}.txt",
            mime="text/plain"
        )

else:
    # Welcome message when no analysis has been run
    st.markdown("---")
    st.markdown(
        """
        <div class="step-container">
            <h3>üöÄ Ready to Transform Patents into Innovation?</h3>
            <p>Upload your patent document and provide your OpenAI API key to begin the AI-powered analysis.</p>
            <p><strong>What you'll get:</strong></p>
            <ul>
                <li>üéØ Key patent themes identification</li>
                <li>üí° Novel product concept generation</li>
                <li>üîß Technical feasibility analysis</li>
                <li>üìà Market opportunity assessment</li>
                <li>‚ú® Complete innovation strategy</li>
                <li>üíæ Downloadable comprehensive report</li>
            </ul>
        </div>
        """, 
        unsafe_allow_html=True
    )
